{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e3e8d6f-ea41-4e23-9ca0-25bb7cb7b2dd",
   "metadata": {},
   "source": [
    "#### Question 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92df1df1-1753-4ba5-8dbb-c7d2209c9f3a",
   "metadata": {},
   "source": [
    "#### Letter I Dataset with Circles\n",
    "\n",
    "In this question, we have created datasets where the **Letter I** is formed using circles. \n",
    "\n",
    "- **Micro-object**: Circle  \n",
    "- **Macro-object**: Letter I  \n",
    "\n",
    "The objective of the model is not only to predict the **number of groups** correctly but also to determine whether the circles, when combined, form the **Letter I** or not. \n",
    "\n",
    "#### Model Performance\n",
    "- Using a **basic CNN model**, the test accuracy achieved was **85%**.\n",
    "- However, the model showed signs of **overfitting**. \n",
    "\n",
    "#### Model Architecture Modification\n",
    "To address overfitting, we replaced the basic CNN with a **VGG architecture**. \n",
    "\n",
    "- With the **current number of epochs set to 5**, we achieved an accuracy of **82%**.  \n",
    "- We aimed to train the model for a **higher number of epochs**, but each epoch took approximately **1 hour**, limiting our ability to run more iterations.\n",
    "- We expect that running the **VGG model** for more epochs would likely increase the test accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3167f2d7-f1ed-4af3-803d-52126a3e5c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and testing datasets generated with 800 training and 100 testing images.\n"
     ]
    }
   ],
   "source": [
    "##Final 1 -- dataset generation of I's\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Directory setup\n",
    "train_dir = 'generalized_proximity/train'\n",
    "test_dir = 'generalized_proximity/test'\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "# Define image size and object properties\n",
    "image_size = (800, 800)  # Image size\n",
    "object_radius = 10  # Radius of small shapes (circles)\n",
    "object_color = (0, 0, 0)  # Color of objects\n",
    "bg_color = (255, 255, 255)  # Background color\n",
    "\n",
    "# Parameters for proximity grouping\n",
    "group_spacing_far = 150  # Spacing between different groups\n",
    "\n",
    "# Function to draw microobjects (only circles)\n",
    "def draw_microobject(image, center_x, center_y):\n",
    "    \"\"\"Draw a small microobject like a circle.\"\"\"\n",
    "    cv2.circle(image, (center_x, center_y), object_radius, object_color, -1)\n",
    "    return image\n",
    "\n",
    "# Function to draw a macroobject (e.g., an 'I' made of circles)\n",
    "def draw_macroobject(image, start_x, start_y, num_microobjects=8):\n",
    "    \"\"\"Draw a macroobject formed by multiple microobjects.\"\"\"\n",
    "    for i in range(num_microobjects):\n",
    "        center_y = start_y + i * (2 * object_radius + 5)  # Adjust vertical spacing\n",
    "        image = draw_microobject(image, start_x, center_y)\n",
    "    return image\n",
    "\n",
    "# Function to draw proximity groups of macroobjects\n",
    "def draw_proximity_groups(image, num_groups=1):\n",
    "    \"\"\"Draw proximity groups, each containing varying numbers of macroobjects.\"\"\"\n",
    "    valid_I_groups = 0  # Track the number of valid \"I\" groups\n",
    "    for group in range(num_groups):\n",
    "        group_start_x = 50 + group * group_spacing_far  # Start position of each group\n",
    "        num_macroobjects = random.randint(1, 4)  # Random number of I's in this group\n",
    "        \n",
    "        # Check if the group can be considered an \"I\"\n",
    "        if num_macroobjects <= 3:\n",
    "            valid_I_groups += 1  # Increment valid group count\n",
    "            \n",
    "        for i in range(num_macroobjects):\n",
    "            start_x = group_start_x + i * (3 * object_radius + 5)  # Adjust horizontal spacing\n",
    "            image = draw_macroobject(image, start_x, 50)\n",
    "    \n",
    "    return image, valid_I_groups  # Return the valid count\n",
    "\n",
    "# Function to generate images with random numbers of groups and varying macroobjects\n",
    "def generate_image(image_num, output_dir, num_groups):\n",
    "    \"\"\"Generates an image with a specified number of groups, each with varying numbers of macroobjects.\"\"\"\n",
    "    img = np.ones((image_size[1], image_size[0], 3), dtype=np.uint8) * 255  # Blank white image\n",
    "    img, valid_I_groups = draw_proximity_groups(img, num_groups=num_groups)\n",
    "\n",
    "    # Save the image with the number of valid \"I\" groups as the filename\n",
    "    # img_name = f\"{valid_I_groups}.png\"\n",
    "    img_name = f\"{valid_I_groups}_{image_num}.png\"\n",
    "    img_path = os.path.join(output_dir, img_name)\n",
    "    cv2.imwrite(img_path, img)\n",
    "\n",
    "# Generate train and test datasets\n",
    "def generate_dataset(num_train, num_test, max_groups=3):\n",
    "    \"\"\"Generates train and test datasets with varying numbers of groups and varying numbers of macroobjects.\"\"\"\n",
    "    for i in range(num_train):\n",
    "        num_groups = random.randint(1, max_groups)  # Random number of groups\n",
    "        generate_image(i, train_dir, num_groups=num_groups)\n",
    "    \n",
    "    for i in range(num_test):\n",
    "        num_groups = random.randint(1, max_groups)  # Random number of groups\n",
    "        generate_image(i, test_dir, num_groups=num_groups)\n",
    "\n",
    "# Define number of images for train and test\n",
    "num_train = 800  # Training images\n",
    "num_test = 100    # Testing images\n",
    "max_groups = 5   # Maximum number of groups in an image\n",
    "\n",
    "# Generate the datasets\n",
    "generate_dataset(num_train, num_test, max_groups=max_groups)\n",
    "\n",
    "print(f\"Training and testing datasets generated with {num_train} training and {num_test} testing images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b07a1c62-7d71-4a91-ba50-e70afa018139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in training set: [0 1 2 3 4 5]\n",
      "Unique labels in testing set: [0 1 2 3 4 5]\n",
      "Epoch 1/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m359s\u001b[0m 17s/step - accuracy: 0.2208 - loss: 23.6576 - val_accuracy: 0.1187 - val_loss: 4.8017\n",
      "Epoch 2/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 16s/step - accuracy: 0.5461 - loss: 1.0995 - val_accuracy: 0.1063 - val_loss: 12.5685\n",
      "Epoch 3/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 16s/step - accuracy: 0.7083 - loss: 0.7220 - val_accuracy: 0.1437 - val_loss: 16.0620\n",
      "Epoch 4/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 16s/step - accuracy: 0.8256 - loss: 0.4408 - val_accuracy: 0.1437 - val_loss: 30.4438\n",
      "Epoch 5/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 14s/step - accuracy: 0.8554 - loss: 0.3728 - val_accuracy: 0.1437 - val_loss: 39.3559\n",
      "Epoch 6/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 13s/step - accuracy: 0.9010 - loss: 0.2523 - val_accuracy: 0.1437 - val_loss: 41.7952\n",
      "Epoch 7/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m335s\u001b[0m 17s/step - accuracy: 0.9082 - loss: 0.2547 - val_accuracy: 0.1437 - val_loss: 55.4583\n",
      "Epoch 8/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 16s/step - accuracy: 0.9145 - loss: 0.2424 - val_accuracy: 0.1437 - val_loss: 57.8349\n",
      "Epoch 9/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 16s/step - accuracy: 0.9399 - loss: 0.1484 - val_accuracy: 0.1437 - val_loss: 70.5254\n",
      "Epoch 10/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 15s/step - accuracy: 0.9337 - loss: 0.1479 - val_accuracy: 0.1437 - val_loss: 82.3479\n",
      "Epoch 11/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 14s/step - accuracy: 0.9411 - loss: 0.1374 - val_accuracy: 0.1437 - val_loss: 83.4962\n",
      "Epoch 12/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m279s\u001b[0m 14s/step - accuracy: 0.9548 - loss: 0.1086 - val_accuracy: 0.1437 - val_loss: 101.2812\n",
      "Epoch 13/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m286s\u001b[0m 14s/step - accuracy: 0.9201 - loss: 0.1567 - val_accuracy: 0.1437 - val_loss: 97.8986\n",
      "Epoch 14/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 16s/step - accuracy: 0.9376 - loss: 0.1338 - val_accuracy: 0.1437 - val_loss: 83.8610\n",
      "Epoch 15/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m288s\u001b[0m 14s/step - accuracy: 0.9610 - loss: 0.1053 - val_accuracy: 0.1437 - val_loss: 104.2838\n",
      "Epoch 16/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 13s/step - accuracy: 0.9657 - loss: 0.0868 - val_accuracy: 0.1437 - val_loss: 121.6152\n",
      "Epoch 17/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 13s/step - accuracy: 0.9701 - loss: 0.0815 - val_accuracy: 0.1437 - val_loss: 134.7983\n",
      "Epoch 18/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 14s/step - accuracy: 0.9455 - loss: 0.1296 - val_accuracy: 0.1437 - val_loss: 75.8596\n",
      "Epoch 19/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m291s\u001b[0m 14s/step - accuracy: 0.9707 - loss: 0.0919 - val_accuracy: 0.1437 - val_loss: 73.8697\n",
      "Epoch 20/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 16s/step - accuracy: 0.9564 - loss: 0.0987 - val_accuracy: 0.1437 - val_loss: 118.3954\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.9171 - loss: 10.7313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8500\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Directory setup\n",
    "train_dir = 'generalized_proximity/train'\n",
    "test_dir = 'generalized_proximity/test'\n",
    "\n",
    "# Parameters\n",
    "image_size = (800, 800)  # Image dimensions\n",
    "num_classes = 6          # Adjust this based on your dataset\n",
    "\n",
    "# Function to load dataset\n",
    "def load_data(data_dir):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        if filename.endswith(\".png\"):\n",
    "            # Load and resize image\n",
    "            img_path = os.path.join(data_dir, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.resize(img, image_size)\n",
    "            images.append(img)\n",
    "            \n",
    "            # Extract label from filename (valid I groups are the first part of the filename)\n",
    "            label = int(filename.split('_')[0])  # Get the number of valid \"I\" groups\n",
    "            labels.append(label)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Load the datasets\n",
    "X_train, y_train = load_data(train_dir)\n",
    "X_test, y_test = load_data(test_dir)\n",
    "\n",
    "# Normalize the images\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "# Check unique labels to understand the range of your dataset\n",
    "print(\"Unique labels in training set:\", np.unique(y_train))\n",
    "print(\"Unique labels in testing set:\", np.unique(y_test))\n",
    "\n",
    "# Validate label range\n",
    "if np.any(y_train >= num_classes) or np.any(y_test >= num_classes):\n",
    "    print(\"Error: Found labels out of range! Adjusting num_classes accordingly.\")\n",
    "\n",
    "# Convert labels to categorical format\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# Define a simple CNN model\n",
    "def create_simple_cnn_model():\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    # Block 1\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(image_size[0], image_size[1], 3)))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # Block 2\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # Block 3\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # Flatten the output and add fully connected layers\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))  # Dropout for regularization\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))  # Output layer for classification\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Compile the model\n",
    "model = create_simple_cnn_model()\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Save the model\n",
    "model.save('simple_cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "93acd59f-e14c-4c88-b135-278226e6a6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in training set: [0 1 2 3 4 5]\n",
      "Unique labels in testing set: [0 1 2 3 4 5]\n",
      "Epoch 1/5\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4077s\u001b[0m 6s/step - accuracy: 0.4460 - loss: 740.0128 - val_accuracy: 0.0000e+00 - val_loss: 7605.6665\n",
      "Epoch 2/5\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4018s\u001b[0m 6s/step - accuracy: 0.7252 - loss: 217.5879 - val_accuracy: 0.1375 - val_loss: 6736.2476\n",
      "Epoch 3/5\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4000s\u001b[0m 6s/step - accuracy: 0.8274 - loss: 72.2046 - val_accuracy: 0.1437 - val_loss: 7400.1108\n",
      "Epoch 4/5\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4020s\u001b[0m 6s/step - accuracy: 0.8854 - loss: 48.8125 - val_accuracy: 0.1187 - val_loss: 7547.6421\n",
      "Epoch 5/5\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4023s\u001b[0m 6s/step - accuracy: 0.9016 - loss: 32.8328 - val_accuracy: 0.1312 - val_loss: 8395.6230\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9s/step - accuracy: 0.8801 - loss: 823.1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8200\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Directory setup\n",
    "train_dir = 'generalized_proximity/train'\n",
    "test_dir = 'generalized_proximity/test'\n",
    "\n",
    "# Parameters\n",
    "image_size = (800, 400)  \n",
    "num_classes = 6         \n",
    "\n",
    "# Function to load dataset\n",
    "def load_data(data_dir):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        if filename.endswith(\".png\"):\n",
    "            # Load and resize image\n",
    "            img_path = os.path.join(data_dir, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.resize(img, image_size)\n",
    "            images.append(img)\n",
    "            \n",
    "            # Extract label from filename (valid I groups are the first part of the filename)\n",
    "            label = int(filename.split('_')[0])  # Get the number of valid \"I\" groups\n",
    "            labels.append(label)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Load the datasets\n",
    "X_train, y_train = load_data(train_dir)\n",
    "X_test, y_test = load_data(test_dir)\n",
    "\n",
    "# Normalize the images\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "# Check unique labels to understand the range of your dataset\n",
    "print(\"Unique labels in training set:\", np.unique(y_train))\n",
    "print(\"Unique labels in testing set:\", np.unique(y_test))\n",
    "\n",
    "# Convert labels to categorical format\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# Define a VGG-like CNN model\n",
    "def create_vgg_model():\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    # Block 1\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(image_size[0], image_size[1], 3)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # Block 2\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # Block 3\n",
    "    model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # Block 4\n",
    "    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # Fully connected layers\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(512, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))  # Dropout for regularization\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))  # Output layer for classification\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Compile the model\n",
    "model = create_vgg_model()\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=1, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Save the model\n",
    "model.save('proximity_vgg_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0652bc-8d33-4844-880e-3772af7b80c3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Acknowledgment:  \n",
    "    This assignment is collaboratively done by:   \n",
    "    Keerthana - 210290  \n",
    "    Meghana - 210073  \n",
    "    Madhuri - 210568  \n",
    "    Shobhit Sharma - 210992"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
