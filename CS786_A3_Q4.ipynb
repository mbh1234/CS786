{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91689a65",
   "metadata": {},
   "source": [
    "#### Q4. Test one other gestalt principle of your choice. For this one, you have to figure out the training and testing strategies for yourselves. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedb4629",
   "metadata": {},
   "source": [
    "We chose \"The principle of Closure\". \n",
    "The principle of closure states that when we look at a complex arrangement of visual elements, we tend to look for a single, recognizable pattern. In other words, when you see an image that has missing parts, your brain will fill in the blanks and make a complete image so you can still recognize the pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a30b135",
   "metadata": {},
   "source": [
    "Here, a dataset containing discountinuous circles, random arcs is generated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb8fce0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data labeled and saved in 'dataset' directory.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Function to generate a reference circle\n",
    "def generate_reference_circle(n, radius=40, thickness=1.2):\n",
    "    image = np.ones((n, n))\n",
    "    center = n // 2  # Center of the image\n",
    "\n",
    "    # Draw the circle\n",
    "    for angle in np.arange(0, 360, 0.1):\n",
    "        rad = np.radians(angle)\n",
    "        x = int(center + radius * np.cos(rad))\n",
    "        y = int(center + radius * np.sin(rad))\n",
    "\n",
    "        # Draw thickness\n",
    "        for t in range(-int(thickness)//2, int(thickness)//2 + 1):\n",
    "            if 0 <= x + t < n:\n",
    "                image[x + t, y] = 0\n",
    "            if 0 <= y + t < n:\n",
    "                image[x, y + t] = 0\n",
    "\n",
    "    return image\n",
    "\n",
    "# Function to generate discontinuous circles with a single gap\n",
    "def generate_discontinuous_circle_with_gap(n, radius=40, gap_angle=36, thickness=1.2):\n",
    "    image = np.ones((n, n))\n",
    "    center = n // 2\n",
    "    gap_position = random.randint(0, 9)  # Random position for the gap (0 to 9)\n",
    "\n",
    "    # Calculate start and end angles for the gap\n",
    "    gap_start_angle = gap_position * gap_angle - gap_angle / 2\n",
    "    gap_end_angle = gap_position * gap_angle + gap_angle / 2\n",
    "\n",
    "    # Draw the circle\n",
    "    for angle in np.arange(0, 360, 0.1):\n",
    "        if not (gap_start_angle <= angle <= gap_end_angle):\n",
    "            rad = np.radians(angle)\n",
    "            x = int(center + radius * np.cos(rad))\n",
    "            y = int(center + radius * np.sin(rad))\n",
    "\n",
    "            # Draw thickness\n",
    "            for t in range(-int(thickness)//2, int(thickness)//2 + 1):\n",
    "                if 0 <= x + t < n:\n",
    "                    image[x + t, y] = 0\n",
    "                if 0 <= y + t < n:\n",
    "                    image[x, y + t] = 0\n",
    "\n",
    "    return image\n",
    "\n",
    "# Function to generate discontinuous circles with multiple gaps\n",
    "def generate_discontinuous_circle_with_multiple_gaps(n, radius=40, num_gaps=5, thickness=1.2, min_gap_length=2, max_gap_length=60):\n",
    "    image = np.ones((n, n))\n",
    "    center = n // 2\n",
    "\n",
    "    # Generate random start positions and lengths for the gaps\n",
    "    gap_positions = [random.uniform(0, 360) for _ in range(num_gaps)]\n",
    "    gap_lengths = [random.uniform(min_gap_length, max_gap_length) for _ in range(num_gaps)]\n",
    "\n",
    "    # Draw the circle with random gaps\n",
    "    for angle in np.arange(0, 360, 0.1):\n",
    "        skip = False\n",
    "        for gap_pos, gap_len in zip(gap_positions, gap_lengths):\n",
    "            if gap_pos <= angle <= gap_pos + gap_len:\n",
    "                skip = True\n",
    "                break\n",
    "        \n",
    "        if skip:\n",
    "            continue  # Skip angles that fall within a gap\n",
    "\n",
    "        # Convert angle to radians\n",
    "        rad = np.radians(angle)\n",
    "        x = int(center + radius * np.cos(rad))\n",
    "        y = int(center + radius * np.sin(rad))\n",
    "\n",
    "        # Draw thickness\n",
    "        for t in range(-int(thickness)//2, int(thickness)//2 + 1):\n",
    "            if 0 <= x + t < n:\n",
    "                image[x + t, y] = 0\n",
    "            if 0 <= y + t < n:\n",
    "                image[x, y + t] = 0\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "# Function to generate random arcs\n",
    "def generate_random_arcs(n, max_radius=40, thickness=1.2, num_arcs=3):\n",
    "    image = np.ones((n, n))\n",
    "\n",
    "    for _ in range(num_arcs):\n",
    "        # Randomly select a center position within the image\n",
    "        center_x = random.randint(0, n-1)\n",
    "        center_y = random.randint(0, n-1)\n",
    "\n",
    "        # Generate a random radius for the arc\n",
    "        radius = random.randint(10, max_radius)\n",
    "\n",
    "        # Randomly select the start and end angles for the arc\n",
    "        start_angle = random.uniform(0, 360)\n",
    "        arc_length = random.uniform(30, 180)  # Length of the arc in degrees\n",
    "        end_angle = start_angle + arc_length\n",
    "\n",
    "        # Draw the arc\n",
    "        for angle in np.arange(start_angle, end_angle, 0.1):\n",
    "            rad = np.radians(angle)\n",
    "            x = int(center_x + radius * np.cos(rad))\n",
    "            y = int(center_y + radius * np.sin(rad))\n",
    "\n",
    "            # Ensure coordinates are within image bounds\n",
    "            if 0 <= x < n and 0 <= y < n:\n",
    "                for t in range(-int(thickness)//2, int(thickness)//2 + 1):\n",
    "                    if 0 <= x + t < n:\n",
    "                        image[x + t, y] = 0\n",
    "                    if 0 <= y + t < n:\n",
    "                        image[x, y + t] = 0\n",
    "\n",
    "    return image\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Parameters\n",
    "n = 100\n",
    "thickness = 1.2\n",
    "radius = 40\n",
    "num_closed_images = 1  # Only 1 reference circle\n",
    "num_discontinuous_1_gap = 10\n",
    "num_discontinuous_5_gaps = 500\n",
    "num_discontinuous_10_gaps = 500\n",
    "num_random_arcs = 100\n",
    "num_discontinuous_30_gaps = 500\n",
    "num_discontinuous_20_gaps = 500\n",
    "\n",
    "# Define directories\n",
    "output_dir = 'dataset'\n",
    "is_circle_dir = os.path.join(output_dir, 'is_circle')\n",
    "closed_dir = os.path.join(is_circle_dir, 'closed')\n",
    "open_dir = os.path.join(is_circle_dir, 'open')\n",
    "not_circle_dir = os.path.join(output_dir, 'not_circle')\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(closed_dir, exist_ok=True)\n",
    "os.makedirs(open_dir, exist_ok=True)\n",
    "os.makedirs(not_circle_dir, exist_ok=True)\n",
    "\n",
    "# Function to save image\n",
    "def save_image(image, folder, name):\n",
    "    plt.imsave(os.path.join(folder, name), image, cmap='gray')\n",
    "\n",
    "# Generate and save images\n",
    "\n",
    "# 1. Reference Circle (Closed)\n",
    "reference_circle = generate_reference_circle(n, radius, thickness)\n",
    "save_image(reference_circle, closed_dir, 'reference_circle.png')\n",
    "\n",
    "# 2. Discontinuous Circles with 1 Gap (Open)\n",
    "for i in range(num_discontinuous_1_gap):\n",
    "    circle_with_1_gap = generate_discontinuous_circle_with_gap(n=n, gap_angle=36, radius=radius, thickness=thickness)\n",
    "    save_image(circle_with_1_gap, open_dir, f'discontinuous_circle_1_gap_{i+1}.png')\n",
    "\n",
    "# 3. Discontinuous Circles with Multiple Gaps (5 Gaps, Open)\n",
    "for i in range(num_discontinuous_5_gaps):\n",
    "    \n",
    "    circle_with_5_gaps = generate_discontinuous_circle_with_multiple_gaps(n=n, num_gaps=5, radius=radius, thickness=thickness, min_gap_length=2, max_gap_length=60)\n",
    "    save_image(circle_with_5_gaps, open_dir, f'discontinuous_circle_5_gaps_{i+1}.png')\n",
    "\n",
    "# 4. Discontinuous Circles with Multiple Gaps (10 Gaps, Open)\n",
    "for i in range(num_discontinuous_10_gaps):\n",
    "    circle_with_10_gaps = generate_discontinuous_circle_with_multiple_gaps(n=n, num_gaps=10, radius=radius, thickness=thickness, min_gap_length=2, max_gap_length=30)\n",
    "    save_image(circle_with_10_gaps, open_dir, f'discontinuous_circle_10_gaps_{i+1}.png')\n",
    "\n",
    "for i in range(num_discontinuous_30_gaps):\n",
    "    circle_with_30_gaps = generate_discontinuous_circle_with_multiple_gaps(n=n, num_gaps=30, radius=radius, thickness=thickness, min_gap_length=2, max_gap_length=30)\n",
    "    save_image(circle_with_30_gaps, open_dir, f'discontinuous_circle_30_gaps_{i+1}.png')    \n",
    "        \n",
    "# 5. Random Arcs (Not Circle)\n",
    "for i in range(num_random_arcs):\n",
    "    random_arcs_image = generate_random_arcs(n=n, num_arcs=random.randint(3, 5), thickness=thickness)\n",
    "    save_image(random_arcs_image, not_circle_dir, f'random_arcs_{i+1}.png')\n",
    "for i in range(num_discontinuous_20_gaps):\n",
    "    circle_with_20_gaps = generate_discontinuous_circle_with_multiple_gaps(n=n, num_gaps=20, radius=radius, thickness=thickness, min_gap_length=20, max_gap_length=60)\n",
    "    save_image(circle_with_20_gaps,  not_circle_dir, f'discontinuous_circle_20_gaps_{i+1}.png')    \n",
    "    \n",
    "\n",
    "print(f\"Data labeled and saved in '{output_dir}' directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e67dc3c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load your images as grayscale\n",
    "complete_circle = cv2.imread('dataset/is_circle/closed/reference_circle.png', cv2.IMREAD_GRAYSCALE)\n",
    "discontinuous_circle = cv2.imread('dataset/is_circle/open/discontinuous_circle_10_gaps_25.png', cv2.IMREAD_GRAYSCALE)\n",
    "random_arcs = cv2.imread('dataset/not_circle/random_arcs_100.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Display the images to verify loading\n",
    "plt.subplot(131), plt.imshow(complete_circle, cmap='gray'), plt.title('Complete Circle')\n",
    "plt.subplot(132), plt.imshow(discontinuous_circle, cmap='gray'), plt.title('Discontinuous Circle')\n",
    "plt.subplot(133), plt.imshow(random_arcs, cmap='gray'), plt.title('Random Arcs')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda858ca",
   "metadata": {},
   "source": [
    "Pixel-Based Similarity (Intersection Over Union Approach):\n",
    "This approach compares how much the two binary images (circle and discontinuous circle) overlap by counting the number of common \"on\" pixels (value = 0, which indicates part of the circle) and dividing by the total number of pixels that belong to either of the two shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd789f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixel-Based Similarity (Discontinuous Circle): 0.5506003430531733\n",
      "Pixel-Based Similarity (Random Arcs): 0.0375\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_pixel_intersection(image1, image2):\n",
    "    # Ensure both images are binary (0 and 1)\n",
    "    binary_image1 = (image1 == 0).astype(np.uint8)\n",
    "    binary_image2 = (image2 == 0).astype(np.uint8)\n",
    "    \n",
    "    # Compute Intersection and Union\n",
    "    intersection = np.logical_and(binary_image1, binary_image2).sum()\n",
    "    union = np.logical_or(binary_image1, binary_image2).sum()\n",
    "    \n",
    "    # Calculate Intersection over Union (IoU)\n",
    "    if union == 0:\n",
    "        return 0  # Avoid division by zero\n",
    "    iou = intersection / union\n",
    "    \n",
    "    return iou\n",
    "\n",
    "# Assuming 'complete_circle', 'discontinuous_circle', and 'random_arcs' are numpy arrays of the images\n",
    "iou_discontinuous = compute_pixel_intersection(complete_circle, discontinuous_circle)\n",
    "iou_random_arcs = compute_pixel_intersection(complete_circle, random_arcs)\n",
    "\n",
    "print(f\"Pixel-Based Similarity (Discontinuous Circle): {iou_discontinuous}\")\n",
    "print(f\"Pixel-Based Similarity (Random Arcs): {iou_random_arcs}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b65cc4",
   "metadata": {},
   "source": [
    " Splitting the Dataset:\n",
    " \n",
    "The following code will create separate directories for training and testing images and label them accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb1c68d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been split into training and testing sets.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Directories\n",
    "open_dir = 'dataset/is_circle/open'\n",
    "not_circle_dir = 'dataset/not_circle'\n",
    "output_train_dir = 'dataset/train'\n",
    "output_test_dir = 'dataset/test'\n",
    "\n",
    "# Create train and test directories\n",
    "os.makedirs(os.path.join(output_train_dir, 'is_circle'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_train_dir, 'not_circle'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_test_dir, 'is_circle'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_test_dir, 'not_circle'), exist_ok=True)\n",
    "\n",
    "# Function to split data\n",
    "def split_data(source_dir, label, test_size=0.2):\n",
    "    images = [img for img in os.listdir(source_dir) if img.endswith('.png')]\n",
    "    train_images, test_images = train_test_split(images, test_size=test_size, random_state=42)\n",
    "\n",
    "    for img in train_images:\n",
    "        shutil.copy(os.path.join(source_dir, img), os.path.join(output_train_dir, label, img))\n",
    "    for img in test_images:\n",
    "        shutil.copy(os.path.join(source_dir, img), os.path.join(output_test_dir, label, img))\n",
    "\n",
    "# Split the datasets\n",
    "split_data(open_dir, 'is_circle')\n",
    "split_data(not_circle_dir, 'not_circle')\n",
    "\n",
    "print(\"Data has been split into training and testing sets.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73cb8e3",
   "metadata": {},
   "source": [
    "Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e9a3cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images: 2088\n",
      "Number of testing images: 522\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Set the paths\n",
    "open_dir = 'dataset/is_circle/open'\n",
    "not_circle_dir = 'dataset/not_circle'\n",
    "reference_circle_path = 'dataset/is_circle/closed/reference_circle.png'\n",
    "\n",
    "# Custom dataset class\n",
    "class CircleDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert('L')  # Load image\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "\n",
    "# Prepare the data\n",
    "open_images = [os.path.join(open_dir, img) for img in os.listdir(open_dir)]\n",
    "not_circle_images = [os.path.join(not_circle_dir, img) for img in os.listdir(not_circle_dir)]\n",
    "\n",
    "# Labels: 1 for is_circle (open), 0 for not_circle\n",
    "open_labels = [1] * len(open_images)\n",
    "not_circle_labels = [0] * len(not_circle_images)\n",
    "\n",
    "# Combine and split datasets\n",
    "all_images = open_images + not_circle_images\n",
    "all_labels = open_labels + not_circle_labels\n",
    "\n",
    "# Split into train and test datasets\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(all_images, all_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((100, 100)),  # Resize to match input size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),  # Normalize\n",
    "])\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = CircleDataset(train_images, train_labels, transform=transform)\n",
    "test_dataset = CircleDataset(test_images, test_labels, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Print the number of images in each dataset\n",
    "print(f'Number of training images: {len(train_dataset)}')\n",
    "print(f'Number of testing images: {len(test_dataset)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c0389f",
   "metadata": {},
   "source": [
    "Defining UNet-based architecture for training CNNs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "608a6cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F  # Import F for activation functions and pooling\n",
    "\n",
    "# Define your MLP (UNet-based architecture) class here\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        # Define layers here, e.g.:\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(32 * 25 * 25, 128)  # Adjust dimensions based on input size\n",
    "        self.fc2 = nn.Linear(128, 1)  # Output layer for binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 32 * 25 * 25)  # Flatten the output, adjust for pooling\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Custom dataset class\n",
    "class CircleDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert('L')  # Load image in grayscale\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "\n",
    "# Set the paths for your dataset\n",
    "open_dir = 'dataset/is_circle/open'\n",
    "not_circle_dir = 'dataset/not_circle'\n",
    "\n",
    "# Prepare the data\n",
    "open_images = [os.path.join(open_dir, img) for img in os.listdir(open_dir)]\n",
    "not_circle_images = [os.path.join(not_circle_dir, img) for img in os.listdir(not_circle_dir)]\n",
    "\n",
    "# Labels: 1 for is_circle (open), 0 for not_circle\n",
    "open_labels = [1] * len(open_images)\n",
    "not_circle_labels = [0] * len(not_circle_images)\n",
    "\n",
    "# Combine and split datasets\n",
    "all_images = open_images + not_circle_images\n",
    "all_labels = open_labels + not_circle_labels\n",
    "\n",
    "# Split into train and test datasets (80% train, 20% test)\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(all_images, all_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((100, 100)),  # Resize to match input size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),  # Normalize\n",
    "])\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = CircleDataset(train_images, train_labels, transform=transform)\n",
    "test_dataset = CircleDataset(test_images, test_labels, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Initialize the model\n",
    "model = MLP()  # Initialize your model\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()  # Binary Cross Entropy\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1819b60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.0541\n",
      "Epoch [2/100], Loss: 0.0450\n",
      "Epoch [3/100], Loss: 0.0304\n",
      "Epoch [4/100], Loss: 0.0301\n",
      "Epoch [5/100], Loss: 0.0342\n",
      "Epoch [6/100], Loss: 0.0213\n",
      "Epoch [7/100], Loss: 0.0251\n",
      "Epoch [8/100], Loss: 0.0238\n",
      "Epoch [9/100], Loss: 0.0140\n",
      "Epoch [10/100], Loss: 0.0124\n",
      "Epoch [11/100], Loss: 0.0086\n",
      "Epoch [12/100], Loss: 0.0120\n",
      "Epoch [13/100], Loss: 0.0096\n",
      "Epoch [14/100], Loss: 0.0098\n",
      "Epoch [15/100], Loss: 0.0110\n",
      "Epoch [16/100], Loss: 0.0044\n",
      "Epoch [17/100], Loss: 0.0043\n",
      "Epoch [18/100], Loss: 0.0035\n",
      "Epoch [19/100], Loss: 0.0023\n",
      "Epoch [20/100], Loss: 0.0022\n",
      "Epoch [21/100], Loss: 0.0017\n",
      "Epoch [22/100], Loss: 0.0015\n",
      "Epoch [23/100], Loss: 0.0012\n",
      "Epoch [24/100], Loss: 0.0013\n",
      "Epoch [25/100], Loss: 0.0010\n",
      "Epoch [26/100], Loss: 0.0011\n",
      "Epoch [27/100], Loss: 0.0013\n",
      "Epoch [28/100], Loss: 0.0008\n",
      "Epoch [29/100], Loss: 0.0007\n",
      "Epoch [30/100], Loss: 0.0006\n",
      "Epoch [31/100], Loss: 0.0006\n",
      "Epoch [32/100], Loss: 0.0006\n",
      "Epoch [33/100], Loss: 0.0005\n",
      "Epoch [34/100], Loss: 0.0005\n",
      "Epoch [35/100], Loss: 0.0005\n",
      "Epoch [36/100], Loss: 0.0004\n",
      "Epoch [37/100], Loss: 0.0005\n",
      "Epoch [38/100], Loss: 0.0004\n",
      "Epoch [39/100], Loss: 0.0004\n",
      "Epoch [40/100], Loss: 0.0004\n",
      "Epoch [41/100], Loss: 0.0003\n",
      "Epoch [42/100], Loss: 0.0003\n",
      "Epoch [43/100], Loss: 0.0003\n",
      "Epoch [44/100], Loss: 0.0003\n",
      "Epoch [45/100], Loss: 0.0002\n",
      "Epoch [46/100], Loss: 0.0002\n",
      "Epoch [47/100], Loss: 0.0002\n",
      "Epoch [48/100], Loss: 0.0002\n",
      "Epoch [49/100], Loss: 0.0002\n",
      "Epoch [50/100], Loss: 0.0002\n",
      "Epoch [51/100], Loss: 0.0002\n",
      "Epoch [52/100], Loss: 0.0002\n",
      "Epoch [53/100], Loss: 0.0002\n",
      "Epoch [54/100], Loss: 0.0002\n",
      "Epoch [55/100], Loss: 0.0002\n",
      "Epoch [56/100], Loss: 0.0001\n",
      "Epoch [57/100], Loss: 0.0001\n",
      "Epoch [58/100], Loss: 0.0001\n",
      "Epoch [59/100], Loss: 0.0001\n",
      "Epoch [60/100], Loss: 0.0001\n",
      "Epoch [61/100], Loss: 0.0001\n",
      "Epoch [62/100], Loss: 0.0001\n",
      "Epoch [63/100], Loss: 0.0001\n",
      "Epoch [64/100], Loss: 0.0001\n",
      "Epoch [65/100], Loss: 0.0001\n",
      "Epoch [66/100], Loss: 0.0001\n",
      "Epoch [67/100], Loss: 0.0001\n",
      "Epoch [68/100], Loss: 0.0001\n",
      "Epoch [69/100], Loss: 0.0001\n",
      "Epoch [70/100], Loss: 0.0001\n",
      "Epoch [71/100], Loss: 0.0001\n",
      "Epoch [72/100], Loss: 0.0001\n",
      "Epoch [73/100], Loss: 0.0001\n",
      "Epoch [74/100], Loss: 0.0001\n",
      "Epoch [75/100], Loss: 0.0001\n",
      "Epoch [76/100], Loss: 0.0001\n",
      "Epoch [77/100], Loss: 0.0000\n",
      "Epoch [78/100], Loss: 0.0000\n",
      "Epoch [79/100], Loss: 0.0000\n",
      "Epoch [80/100], Loss: 0.0000\n",
      "Epoch [81/100], Loss: 0.0000\n",
      "Epoch [82/100], Loss: 0.0000\n",
      "Epoch [83/100], Loss: 0.0000\n",
      "Epoch [84/100], Loss: 0.0000\n",
      "Epoch [85/100], Loss: 0.0000\n",
      "Epoch [86/100], Loss: 0.0000\n",
      "Epoch [87/100], Loss: 0.0000\n",
      "Epoch [88/100], Loss: 0.0000\n",
      "Epoch [89/100], Loss: 0.0000\n",
      "Epoch [90/100], Loss: 0.0000\n",
      "Epoch [91/100], Loss: 0.0000\n",
      "Epoch [92/100], Loss: 0.0000\n",
      "Epoch [93/100], Loss: 0.0000\n",
      "Epoch [94/100], Loss: 0.0000\n",
      "Epoch [95/100], Loss: 0.0000\n",
      "Epoch [96/100], Loss: 0.0000\n",
      "Epoch [97/100], Loss: 0.0000\n",
      "Epoch [98/100], Loss: 0.0000\n",
      "Epoch [99/100], Loss: 0.0000\n",
      "Epoch [100/100], Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 100  # Adjust as needed\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()  # Clear the gradients\n",
    "        outputs = model(images)  # Forward pass\n",
    "        loss = criterion(outputs.squeeze(), labels.float())  # Calculate loss\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update parameters\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7577b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test set: 98.08%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation loop\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        predicted = (torch.sigmoid(outputs) > 0.5).float()  # Apply sigmoid and threshold\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted.squeeze() == labels.float()).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy of the model on the test set: {accuracy:.2f}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ac166d",
   "metadata": {},
   "source": [
    "Acknowledgment:  \n",
    "    This assignment is collaboratively done by:   \n",
    "    Keerthana - 210290  \n",
    "    Meghana - 210073  \n",
    "    Madhuri - 210568  \n",
    "    Shobhit Sharma - 210992  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
